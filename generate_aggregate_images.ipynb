{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e1da4-f142-42a6-8287-c0174d0570c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from data.personas import *\n",
    "from data.constants import MODEL_ORDER\n",
    "from data.loader import load_data\n",
    "from utils.significance_testing import *\n",
    "from utils.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ede167-cbc1-4a01-a5b3-4b81c73aa9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283eb72-1d09-4514-94d0-4206f0bb73b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_metrics = {\n",
    "    'OP': \"Exp. Advantage: Static \\n(e.g., expert in fact-checking)\",\n",
    "    \"level1\": \" Exp. Advantage: Broad \\n(e.g., expert in math)\",\n",
    "    \"level2\": \"Exp. Advantage: Focused\\n(e.g., expert in abstract algebra)\",\n",
    "    \"level3\": \"Exp. Advantage: Niche\\n(e.g., expert in group theory)\",\n",
    "    'WU_color': \"Robustness\\n(Color)\",\n",
    "    'WU_name': \"Robustness\\n(Name)\",\n",
    "    'Fid_Ed': \"Fidelity\\n(education)\", \n",
    "    \"Fid_Exp\": \"Fidelity\\n(domain match)\",\n",
    "    'Fid_ExpLevel': \"Fidelity\\n(specialization)\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bae23-7dd9-478f-b616-5c20f0ffd9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expertise_metrics = [\"OP\", \"level1\", \"level2\", \"level3\"]\n",
    "robustness_metrics = ['WU_color', 'WU_name']\n",
    "fidelity_metrics = [ 'Fid_Ed', \"Fid_Exp\", 'Fid_ExpLevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513c105-769e-4ff5-89a6-4d151859e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dfs = {}\n",
    "task2persona = {}\n",
    "persona2task = {}\n",
    "all_categories = {}\n",
    "\n",
    "dataset_order = [\"truthfulqa\", \"gsm8k\", \"mmlu_pro\", \"bigbench\", \"math\"]\n",
    "\n",
    "for dataset in dataset_order:\n",
    "    print(f\"Loading and processing {dataset}.\")\n",
    "    dataset_dfs[dataset] = load_data(dataset).to_pandas()\n",
    "    if dataset == \"mmlu_pro\":\n",
    "        persona2task[\"mmlu_pro\"] = {x: \"other\" if x == \"an expert in miscellaneous fields including international relations, sociology, accounting, and human sexuality\" else x.replace(\"an expert in \", \"\") for x in EXPERTS[\"mmlu_pro\"]}\n",
    "        all_categories[\"mmlu_pro\"] = dataset_dfs[\"mmlu_pro\"][\"category\"]\n",
    "    elif dataset == \"bigbench\":\n",
    "        experts = EXPERTS[\"bigbench\"]\n",
    "        tasks = ['contextual_parametric_knowledge_conflicts',\n",
    "                'logic_grid_puzzle',\n",
    "                'strategyqa',\n",
    "                'tracking_shuffled_objects']\n",
    "        persona2task[\"bigbench\"] = {\n",
    "                                        experts[0]: tasks[1],\n",
    "                                        experts[1]: tasks[2],\n",
    "                                        experts[2]: tasks[3],\n",
    "                                        experts[3]: tasks[0]\n",
    "                                    }\n",
    "        all_categories[\"bigbench\"] = dataset_dfs[\"bigbench\"][\"category\"]\n",
    "    elif dataset == \"math\":\n",
    "        experts = EXPERTS[dataset][1:8]\n",
    "        tasks =  ['Algebra',\n",
    "                'Counting & Probability',\n",
    "                'Geometry',\n",
    "                'Intermediate Algebra',\n",
    "                'Number Theory',\n",
    "                'Prealgebra',\n",
    "                'Precalculus']\n",
    "        persona2task[\"math\"] = {p: s for p, s in zip(experts, tasks)}\n",
    "        all_categories[\"math\"] = dataset_dfs[\"math\"][\"type\"]\n",
    "\n",
    "for k, v in persona2task.items():\n",
    "    task2persona[k] = {value: key for key,value in v.items()}\n",
    "\n",
    "\n",
    "task_to_dataset = {\n",
    "    \"truthfulqa\": \"truthfulqa\",\n",
    "    \"gsm8k\": \"gsm8k\",\n",
    "}\n",
    "mmlu_tasks = {x: \"mmlu_pro\" for x in task2persona[\"mmlu_pro\"].keys()}\n",
    "bigbench_tasks = {x: \"bigbench\" for x in task2persona[\"bigbench\"].keys()}\n",
    "math_tasks = {x: \"math\" for x in task2persona[\"math\"].keys()}\n",
    "task_to_dataset = {**task_to_dataset, **mmlu_tasks, **bigbench_tasks, **math_tasks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b752e-c5d6-473b-9ee8-95405b9e87c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [expertise_metrics, robustness_metrics, fidelity_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545822b-3f1b-4c5c-b94b-8b51c8a25a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "print(sorted(fm.get_font_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170409a-1ccf-4a58-8e0a-04cc4be95b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.fontManager.addfont(\"/usr/share/fonts/truetype/cmu/cmunrm.ttf\")   # regular\n",
    "fm.fontManager.addfont(\"/usr/share/fonts/truetype/cmu/cmunbx.ttf\")   # bold\n",
    "bold_font = fm.FontProperties(fname=\"/usr/share/fonts/truetype/cmu/cmunbx.ttf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d920b-9b46-4aa0-a120-1dd19cd4b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_serif = fm.FontProperties(fname=\"/usr/share/fonts/truetype/cmu/cmunrm.ttf\").get_name()\n",
    "print(\"Font name:\", cmu_serif)  # should be \"CMU Serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9efe4df-93ad-4149-8bc3-ed03e4fb8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,  # Enable LaTeX\n",
    "    \"mathtext.fontset\": \"cm\",  # Use Computer Modern (LaTeX default)\n",
    "    \"font.family\": cmu_serif,\n",
    "    \"font.size\": 14,         # Base font size\n",
    "    \"axes.titlesize\": 16,    # Title font size\n",
    "    \"axes.labelsize\": 14,    # Axis label font size\n",
    "    \"xtick.labelsize\": 12,   # X-axis tick font size\n",
    "    \"ytick.labelsize\": 12,   # Y-axis tick font size\n",
    "    \"legend.fontsize\": 14    # Legend font size\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac105259-273e-46f4-b9b2-2aa24917b55b",
   "metadata": {},
   "source": [
    "### Make Dataset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de82854-6782-422b-aa95-e2c7d83e0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2ab6f-7818-4c88-b6ae-9108f5140706",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(dataset_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961addc-94cb-448f-b2b5-8c2143048631",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for dataset in datasets:\n",
    "    if dataset in all_categories:\n",
    "        tasks.extend(np.unique(all_categories[dataset]))\n",
    "    else:\n",
    "        tasks.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b64d41-ff45-45fa-8a9e-3be6a124c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"Task\"] = tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c8885-f4d7-4a6a-85d6-4d5df0f5a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"Dataset\"] = table.Task.apply(lambda x: task_to_dataset[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3f57a-39f1-41dc-b2c8-77d7a7a839b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for task in table.Task.tolist():\n",
    "    dataset = task_to_dataset[task]\n",
    "    if dataset in [\"truthfulqa\", \"gsm8k\"]:\n",
    "        samples.append(len(dataset_dfs[dataset]))\n",
    "    else:\n",
    "        if dataset != \"math\":\n",
    "            counts = dataset_dfs[dataset].category.value_counts()\n",
    "        else:\n",
    "            counts = dataset_dfs[dataset].type.value_counts()\n",
    "        samples.append(counts.loc[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28da9a-7c2a-42ba-9c2b-c9a51dab8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"# Instances\"] = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318be245-ac4d-479d-8fec-fa73106d4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[[\"Dataset\", \"Task\", \"# Instances\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d3f25-1edf-4f3f-b889-ee151cbdc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"Task\"] = table[\"Task\"].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf2be4-2e59-4d3e-8371-58476ebd24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in dataset_dfs.values():\n",
    "    count += len(data)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95683a-18e8-4695-a41a-9723a01477de",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"# Instances\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60c6a0-a10c-4642-aa9f-e2be1fc04231",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807747b-fdc3-4c23-a62f-26c307ac10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da7b48-0d17-410d-8e8d-b0b102589887",
   "metadata": {},
   "source": [
    "### Aggregate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6343410-b7f9-4428-97d3-6b3370ca3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitigation = \"base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddba73-cc4b-45c9-9847-b77ea3ea43c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pickle.load(open(f\"./results/all_metrics.pkl\", \"rb\"))\n",
    "pvalues = pickle.load(open(f\"./results/all_pvalues.pkl\", \"rb\"))\n",
    "all_results = pickle.load(open(f\"./results/all_results.pkl\", \"rb\"))\n",
    "significances = pickle.load(open(f\"./results/fidelity_significances.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa23aa-6b11-4c59-8c0b-e83c6f217f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significances(metric, task, model):\n",
    "    if metric == \"OP\":\n",
    "        pvalue = pvalues[task].loc[\"in-expert\", model]\n",
    "    if metric == \"WU_color\":\n",
    "        worst = worst_case_utility(all_results[task], COLOR_PERSONAS, return_persona=True)[1][model]\n",
    "        pvalue = pvalues[task].loc[worst, model]\n",
    "    if metric == \"WU_name\":\n",
    "        worst = worst_case_utility(all_results[task], NAMES, return_persona=True)[1][model]\n",
    "        pvalue = pvalues[task].loc[worst, model]\n",
    "    if \"level\" in metric:\n",
    "        pvalue =  pvalues[task].loc[metric, model]\n",
    "    if \"Fid\" in metric:\n",
    "        return significances[task].loc[metric, model]\n",
    "    else:\n",
    "        return pvalue < .05    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db7e821-f562-4859-9bd8-2ffc7b7ebfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(metrics_df, comp=False):\n",
    "    metrics_df = metrics_df[metrics_df.metric != \"empty\"].copy()\n",
    "    metrics_df[\"significant\"] = metrics_df.apply(lambda x: get_significances(x.metric, x.task, x.model), axis=1)\n",
    "    metrics_df.score = metrics_df.apply(lambda x: 1 if x.score > 0 and x.significant else (-1 if x.score < 0 and x.significant else 0),axis=1) \n",
    "\n",
    "    metrics_df = metrics_df.groupby([\"metric\", \"model\"], as_index=False).score.value_counts()\n",
    "    \n",
    "    model_type = pd.CategoricalDtype(categories=MODEL_ORDER, ordered=True)\n",
    "    \n",
    "    metrics_df.model = metrics_df.model.astype(model_type)        \n",
    "    \n",
    "    metrics_df.model = metrics_df.model.apply(lambda x: \"-\".join(x.split(\"-\")[:-1]))\n",
    "    \n",
    "    metrics_df[\"percent\"] = metrics_df[\"count\"] / 27 * 100\n",
    "    metric_dfs = []\n",
    "    for idx, metrics in enumerate(metric_names):\n",
    "        metric_type = pd.CategoricalDtype(categories=metrics, ordered=True)\n",
    "        metrics_df_filtered = metrics_df[metrics_df.metric.isin(metrics)].copy()\n",
    "        metrics_df_filtered.metric = metrics_df_filtered.metric.astype(metric_type)\n",
    "        mapping = [\"Negative\", \"Not significant\", \"Positive\"]\n",
    "        # if idx == 0:\n",
    "        #     mapping[0] = mapping[0] + \" ❌\"\n",
    "        #     mapping[1] = mapping[1] + \" ✅\"\n",
    "        #     mapping[2] = mapping[2] + \" ✅\"\n",
    "        # elif idx == 1:\n",
    "        #     mapping[0] = mapping[0] + \" ❌\"\n",
    "        #     mapping[1] = mapping[1] + \" ✅\"\n",
    "        #     mapping[2] = mapping[2] + \" ❌\"\n",
    "        # elif idx == 2:\n",
    "        #     mapping[0] = mapping[0] + \" ❌\"\n",
    "        #     mapping[1] = mapping[1] + \" ❌\"\n",
    "        #     mapping[2] = mapping[2] + \" ✅\"\n",
    "        metrics_df_filtered.score = metrics_df_filtered.score.apply(lambda x: mapping[x+1])\n",
    "        metrics_df_filtered.score = metrics_df_filtered.score.astype(pd.CategoricalDtype(categories=mapping, ordered=True))\n",
    "        metrics_df_filtered = metrics_df_filtered.sort_values([\"metric\", \"model\", \"score\"])\n",
    "        metric_dfs.append(metrics_df_filtered)\n",
    "    \n",
    "    return metric_dfs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ca6fc-a28a-45b6-91fd-eb442cb12ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "for task, df in metrics.items():\n",
    "    ms = df.T.stack().reset_index().copy()\n",
    "    ms[\"task\"] = task\n",
    "    ms.columns = [\"model\", \"metric\", \"score\", \"task\"]\n",
    "    metrics_df =  pd.concat([metrics_df, ms], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c82f8-a2e0-4fd2-8735-ae98e21e5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, df in all_results.items():\n",
    "    expertise_df = df.loc[[\"level1\", \"level2\", \"level3\"]].copy()\n",
    "    expertise_df = expertise_df - df.loc[[\"empty\"]].values\n",
    "    ms = expertise_df.T.stack().reset_index()\n",
    "    ms[\"task\"] = task\n",
    "    ms.columns = [\"model\", \"metric\", \"score\", \"task\"]\n",
    "    metrics_df =  pd.concat([metrics_df, ms], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d366538-891c-43ed-999f-675e98b1914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expertise_df, robustness_df, fidelity_df = process_df(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47d160-9701-4f92-9fe0-78ed934f7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(expertise_df, col=\"metric\", sharey=True, sharex=True, col_wrap=2, height=4, aspect=.95)\n",
    "for idx, (ax, (metric, sub_df)) in enumerate(zip(g.axes.flat, expertise_df.groupby(\"metric\"))):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=12, color=\"black\", fontproperties=bold_font)\n",
    "                #if score not in [\"Not significant\", \"Positive\"]:\n",
    "                    #rect.set_hatch(\"**\")\n",
    "                    #rect.set_alpha(.3)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    if idx //2==1:\n",
    "        sec2 = ax.secondary_xaxis(location=0)\n",
    "        sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "        sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font)\n",
    "    ax.set_ylabel(\"# of Tasks\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "#legend = g.axes.flat[1].legend(loc='upper center',  bbox_to_anchor=(.0, 1.35), ncol=3)\n",
    "\n",
    "# g.fig.suptitle(\"Expertise advantage\", fontproperties=bold_font, y=1.22)er\", va=\"bottom\",\n",
    "plt.subplots_adjust(wspace=.07, hspace=.25)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e76dcb-103f-4ccc-9a8c-342c8cb6fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/expertise_aggregate_base.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7da1a4-0252-4ce1-89df-db59da38a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(robustness_df, col=\"metric\", sharey=True, col_wrap=2, height=4, aspect=.95)\n",
    "for ax, (metric, sub_df) in zip(g.axes.flat, robustness_df.groupby(\"metric\")):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=12, color=\"black\", fontproperties=bold_font)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "    sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font)\n",
    "    ax.set_ylabel(\"# of Tasks\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "#g.axes.flat[0].legend(loc='upper center',  bbox_to_anchor=(1., 1.35), ncol=3)\n",
    "# g.fig.suptitle(\"Persona vs No-Persona\", fontproperties=bold_font, y=1.22)\n",
    "plt.subplots_adjust(wspace=.05, hspace=0)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb953c38-9ab8-4c27-a709-be1ee0692185",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/robustness_aggregate_base.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b25e4f-be37-447b-a4ca-2c69b8d62c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(fidelity_df, col=\"metric\", sharey=True, sharex=True, col_wrap=3, height=4, aspect=.95)\n",
    "for ax, (metric, sub_df) in zip(g.axes.flat, fidelity_df.groupby(\"metric\")):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=14, color=\"black\", fontproperties=bold_font)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    #if \"xp\" in metric:\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "    sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font, fontsize=18)\n",
    "    ax.set_ylabel(\"# of Tasks\", fontsize=18)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    ax.xaxis.set_tick_params(labelsize=16)\n",
    "\n",
    "#g.axes.flat[0].legend(loc='lower right',  bbox_to_anchor=(1.85, -.85), ncol=1)\n",
    "plt.subplots_adjust(wspace=.07, hspace=.25)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fba13a-10f2-4bea-9a1a-fc8a5bf55850",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(\"../persona_performance_paper/media/fidelity_aggregate_base.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9c327-3cf6-4fc7-92f5-ce94b879c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitigation = \"instruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477683d-3fbf-4a9a-9485-9df07c862d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pickle.load(open(f\"./results/{mitigation}/all_metrics.pkl\", \"rb\"))\n",
    "pvalues = pickle.load(open(f\"./results/{mitigation}/all_pvalues.pkl\", \"rb\"))\n",
    "all_results = pickle.load(open(f\"./results/{mitigation}/all_results.pkl\", \"rb\"))\n",
    "significances = pickle.load(open(f\"./results/{mitigation}/fidelity_significances.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784810e4-b5f1-46e4-8a3f-ff2d1ac179cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significances(metric, task, model):\n",
    "    if metric == \"OP\":\n",
    "        pvalue = pvalues[task].loc[\"in-expert\", model]\n",
    "    if metric == \"WU_color\":\n",
    "        worst = worst_case_utility(all_results[task], COLOR_PERSONAS, return_persona=True)[1][model]\n",
    "        pvalue = pvalues[task].loc[worst, model]\n",
    "    if metric == \"WU_name\":\n",
    "        worst = worst_case_utility(all_results[task], NAMES, return_persona=True)[1][model]\n",
    "        pvalue = pvalues[task].loc[worst, model]\n",
    "    if \"level\" in metric:\n",
    "        pvalue =  pvalues[task].loc[metric, model]\n",
    "    if \"Fid\" in metric:\n",
    "        return significances[task].loc[metric, model]\n",
    "    else:\n",
    "        return pvalue < .05    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53a7b1-0824-4604-b4fa-28244051a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "for task, df in metrics.items():\n",
    "    ms = df.T.stack().reset_index().copy()\n",
    "    ms[\"task\"] = task\n",
    "    ms.columns = [\"model\", \"metric\", \"score\", \"task\"]\n",
    "    metrics_df =  pd.concat([metrics_df, ms], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb78408-9fe7-43ec-96ac-2a64ab1ae988",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, df in all_results.items():\n",
    "    expertise_df = df.loc[[\"level1\", \"level2\", \"level3\"]].copy()\n",
    "    expertise_df = expertise_df - df.loc[[\"empty\"]].values\n",
    "    ms = expertise_df.T.stack().reset_index()\n",
    "    ms[\"task\"] = task\n",
    "    ms.columns = [\"model\", \"metric\", \"score\", \"task\"]\n",
    "    metrics_df =  pd.concat([metrics_df, ms], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac69997-cb0e-499c-9f2d-45207cd37600",
   "metadata": {},
   "outputs": [],
   "source": [
    "expertise_df, robustness_df, fidelity_df = process_df(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dab90e-5b17-4721-b67e-d01157a5acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(expertise_df, col=\"metric\", sharey=True, sharex=True, col_wrap=2, height=4, aspect=.95)\n",
    "for idx, (ax, (metric, sub_df)) in enumerate(zip(g.axes.flat, expertise_df.groupby(\"metric\"))):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=12, color=\"black\", fontproperties=bold_font)\n",
    "                #if score not in [\"Not significant\", \"Positive\"]:\n",
    "                    #rect.set_hatch(\"**\")\n",
    "                    #rect.set_alpha(.3)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    if idx //2==1:\n",
    "        sec2 = ax.secondary_xaxis(location=0)\n",
    "        sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "        sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font)\n",
    "    ax.set_ylabel(\"# of Tasks\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "#legend = g.axes.flat[1].legend(loc='upper center',  bbox_to_anchor=(.0, 1.35), ncol=3)\n",
    "\n",
    "g.fig.suptitle(\"Instruction\", fontproperties=bold_font, y=1.05, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.07, hspace=.25)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c14184-f373-42cc-9c10-c4ce440a1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/expertise_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec43a3f-3d28-43e3-978e-83efd203d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(robustness_df, col=\"metric\", sharey=True, col_wrap=2, height=4, aspect=.95)\n",
    "for ax, (metric, sub_df) in zip(g.axes.flat, robustness_df.groupby(\"metric\")):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=12, color=\"black\", fontproperties=bold_font)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "    sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font)\n",
    "    ax.set_ylabel(\"# of Tasks\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "#g.axes.flat[0].legend(loc='upper center',  bbox_to_anchor=(1., 1.35), ncol=3)\n",
    "# g.fig.suptitle(\"Persona vs No-Persona\", fontproperties=bold_font, y=1.22)\n",
    "g.fig.suptitle(\"Instruction\", fontproperties=bold_font, y=1.05, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.05, hspace=0)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81985e66-acb7-4474-94c7-ef07d746eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/robustness_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac471776-2ced-4159-a575-1fe1caac59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(fidelity_df, col=\"metric\", sharey=True, sharex=True, col_wrap=3, height=4, aspect=.95)\n",
    "for ax, (metric, sub_df) in zip(g.axes.flat, fidelity_df.groupby(\"metric\")):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=14, color=\"black\", fontproperties=bold_font)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    #if \"xp\" in metric:\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "    sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font, fontsize=18)\n",
    "    ax.set_ylabel(\"# of Tasks\", fontsize=18)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    ax.xaxis.set_tick_params(labelsize=16)\n",
    "\n",
    "#g.axes.flat[0].legend(loc='lower right',  bbox_to_anchor=(1.85, -.85), ncol=1)\n",
    "g.fig.suptitle(\"Instruction\", fontproperties=bold_font, y=1.1, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.07, hspace=.25)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7214b-20ce-4564-8245-9a75904ff74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/fidelity_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad2b51-e549-4e29-9daa-6ddff55b80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitigation = \"refine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27f4cc-66f1-41b1-8835-c28a67abe0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pickle.load(open(f\"./results/{mitigation}/all_metrics.pkl\", \"rb\"))\n",
    "pvalues = pickle.load(open(f\"./results/{mitigation}/all_pvalues.pkl\", \"rb\"))\n",
    "all_results = pickle.load(open(f\"./results/{mitigation}/all_results.pkl\", \"rb\"))\n",
    "significances = pickle.load(open(f\"./results/{mitigation}/fidelity_significances.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e4359-0f76-4feb-ba73-82170d2a466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significances(metric, task, model):\n",
    "    if metric == \"OP\":\n",
    "        pvalue = pvalues[task].loc[\"in-expert\", model]\n",
    "    if metric == \"WU_color\":\n",
    "        worst = worst_case_utility(all_results[task], COLOR_PERSONAS, return_persona=True)[1][model]\n",
    "        pvalue = pvalues[task].loc[worst, model]\n",
    "    if metric == \"WU_name\":\n",
    "        worst = worst_case_utility(all_results[task], NAMES, return_persona=True)[1][model]\n",
    "        pvalue = pvalues[task].loc[worst, model]\n",
    "    if \"level\" in metric:\n",
    "        pvalue =  pvalues[task].loc[metric, model]\n",
    "    if \"Fid\" in metric:\n",
    "        return significances[task].loc[metric, model]\n",
    "    else:\n",
    "        return pvalue < .05    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957fccd-86b8-42ce-9bf1-49f114aac806",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "for task, df in metrics.items():\n",
    "    ms = df.T.stack().reset_index().copy()\n",
    "    ms[\"task\"] = task\n",
    "    ms.columns = [\"model\", \"metric\", \"score\", \"task\"]\n",
    "    metrics_df =  pd.concat([metrics_df, ms], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0662f9-e714-4657-adb1-c2057b324ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, df in all_results.items():\n",
    "    expertise_df = df.loc[[\"level1\", \"level2\", \"level3\"]].copy()\n",
    "    expertise_df = expertise_df - df.loc[[\"empty\"]].values\n",
    "    ms = expertise_df.T.stack().reset_index()\n",
    "    ms[\"task\"] = task\n",
    "    ms.columns = [\"model\", \"metric\", \"score\", \"task\"]\n",
    "    metrics_df =  pd.concat([metrics_df, ms], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab50264-bf48-4a05-9404-1dbee0f166c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expertise_df, robustness_df, fidelity_df = process_df(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aabab4-3c5f-42a7-9b72-f6ec8a57a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(expertise_df, col=\"metric\", sharey=True, sharex=True, col_wrap=2, height=4, aspect=.95)\n",
    "for idx, (ax, (metric, sub_df)) in enumerate(zip(g.axes.flat, expertise_df.groupby(\"metric\"))):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=12, color=\"black\", fontproperties=bold_font)\n",
    "                #if score not in [\"Not significant\", \"Positive\"]:\n",
    "                    #rect.set_hatch(\"**\")\n",
    "                    #rect.set_alpha(.3)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    if idx //2==1:\n",
    "        sec2 = ax.secondary_xaxis(location=0)\n",
    "        sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "        sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font)\n",
    "    ax.set_ylabel(\"# of Tasks\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "#legend = g.axes.flat[1].legend(loc='upper center',  bbox_to_anchor=(.0, 1.35), ncol=3)\n",
    "\n",
    "# g.fig.suptitle(\"Expertise advantage\", fontproperties=bold_font, y=1.22)er\", va=\"bottom\",\n",
    "g.fig.suptitle(\"Refine + Instruction\", fontproperties=bold_font, y=1.05, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.07, hspace=.25)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d78aa6-ee7d-4888-be30-f0670170bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/expertise_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e1a58-cfe8-455c-8d4b-6c9318a4cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(robustness_df, col=\"metric\", sharey=True, col_wrap=2, height=4, aspect=.95)\n",
    "for ax, (metric, sub_df) in zip(g.axes.flat, robustness_df.groupby(\"metric\")):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=12, color=\"black\", fontproperties=bold_font)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "    sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font)\n",
    "    ax.set_ylabel(\"# of Tasks\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "#g.axes.flat[0].legend(loc='upper center',  bbox_to_anchor=(1., 1.35), ncol=3)\n",
    "# g.fig.suptitle(\"Persona vs No-Persona\", fontproperties=bold_font, y=1.22)\n",
    "g.fig.suptitle(\"Refine + Instruction\", fontproperties=bold_font, y=1.08, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.05, hspace=0)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fca3e9-c89c-44c2-8e1b-00da20f69aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/robustness_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416f58d-7033-4bfd-8be7-d3173ab91d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(fidelity_df, col=\"metric\", sharey=True, sharex=True, col_wrap=3, height=4, aspect=.95)\n",
    "for ax, (metric, sub_df) in zip(g.axes.flat, fidelity_df.groupby(\"metric\")):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=14, color=\"black\", fontproperties=bold_font)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    #if \"xp\" in metric:\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "    sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font, fontsize=18)\n",
    "    ax.set_ylabel(\"# of Tasks\", fontsize=18)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    ax.xaxis.set_tick_params(labelsize=16)\n",
    "\n",
    "#g.axes.flat[0].legend(loc='lower right',  bbox_to_anchor=(1.85, -.85), ncol=1)\n",
    "g.fig.suptitle(\"Refine + Instruction\", fontproperties=bold_font, y=1.1, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.07, hspace=.25)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814bfce-dd58-4ff2-a039-932953238f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/fidelity_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99360b3f-ba1d-427d-b0ab-a1d5819f9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitigation = \"refine_basic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b3f7e-5029-4ed2-8fa2-8d254678a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pickle.load(open(f\"./results/{mitigation}/all_metrics.pkl\", \"rb\"))\n",
    "pvalues = pickle.load(open(f\"./results/{mitigation}/all_pvalues.pkl\", \"rb\"))\n",
    "all_results = pickle.load(open(f\"./results/{mitigation}/all_results.pkl\", \"rb\"))\n",
    "significances = pickle.load(open(f\"./results/{mitigation}/fidelity_significances.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c126882-52b2-4c9d-9f12-e6c0a3418be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significances(metric, task, model):\n",
    "    if metric == \"OP\":\n",
    "        pvalue = pvalues[task].loc[\"in-expert\", model]\n",
    "    if metric == \"WU_color\":\n",
    "        worst = worst_case_utility(all_results[task], COLOR_PERSONAS, return_persona=True)[1][model]\n",
    "        pvalue = pvalues[task].loc[worst, model]\n",
    "    if metric == \"WU_name\":\n",
    "        worst = worst_case_utility(all_results[task], NAMES, return_persona=True)[1][model]\n",
    "        pvalue = pvalues[task].loc[worst, model]\n",
    "    if \"level\" in metric:\n",
    "        pvalue =  pvalues[task].loc[metric, model]\n",
    "    if \"Fid\" in metric:\n",
    "        return significances[task].loc[metric, model]\n",
    "    else:\n",
    "        return pvalue < .05    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e71ae1-4ccc-4f00-8b61-8e989f6c22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "for task, df in metrics.items():\n",
    "    ms = df.T.stack().reset_index().copy()\n",
    "    ms[\"task\"] = task\n",
    "    ms.columns = [\"model\", \"metric\", \"score\", \"task\"]\n",
    "    metrics_df =  pd.concat([metrics_df, ms], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79134c2-5f9a-4168-bb67-617bc3a9aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, df in all_results.items():\n",
    "    expertise_df = df.loc[[\"level1\", \"level2\", \"level3\"]].copy()\n",
    "    expertise_df = expertise_df - df.loc[[\"empty\"]].values\n",
    "    ms = expertise_df.T.stack().reset_index()\n",
    "    ms[\"task\"] = task\n",
    "    ms.columns = [\"model\", \"metric\", \"score\", \"task\"]\n",
    "    metrics_df =  pd.concat([metrics_df, ms], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c797aa8-d8a4-4276-a79e-df8f8bb19279",
   "metadata": {},
   "outputs": [],
   "source": [
    "expertise_df, robustness_df, fidelity_df = process_df(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd32f6-136d-4c6a-a689-f9c8f2f209d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(expertise_df, col=\"metric\", sharey=True, sharex=True, col_wrap=2, height=4, aspect=.95)\n",
    "for idx, (ax, (metric, sub_df)) in enumerate(zip(g.axes.flat, expertise_df.groupby(\"metric\"))):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=12, color=\"black\", fontproperties=bold_font)\n",
    "                #if score not in [\"Not significant\", \"Positive\"]:\n",
    "                    #rect.set_hatch(\"**\")\n",
    "                    #rect.set_alpha(.3)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    if idx //2==1:\n",
    "        sec2 = ax.secondary_xaxis(location=0)\n",
    "        sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "        sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font)\n",
    "    ax.set_ylabel(\"# of Tasks\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "#legend = g.axes.flat[1].legend(loc='upper center',  bbox_to_anchor=(.0, 1.35), ncol=3)\n",
    "\n",
    "# g.fig.suptitle(\"Expertise advantage\", fontproperties=bold_font, y=1.22)er\", va=\"bottom\",\n",
    "g.fig.suptitle(\"Refine\", fontproperties=bold_font, y=1.05, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.07, hspace=.25)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5a24c-0c2f-428f-8bf0-e5b2d4076c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/expertise_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d4364-9bd8-4605-871c-819f86ee443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(robustness_df, col=\"metric\", sharey=True, col_wrap=2, height=4, aspect=.95)\n",
    "for ax, (metric, sub_df) in zip(g.axes.flat, robustness_df.groupby(\"metric\")):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=12, color=\"black\", fontproperties=bold_font)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "    sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font)\n",
    "    ax.set_ylabel(\"# of Tasks\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "#g.axes.flat[0].legend(loc='upper center',  bbox_to_anchor=(1., 1.35), ncol=3)\n",
    "# g.fig.suptitle(\"Persona vs No-Persona\", fontproperties=bold_font, y=1.22)\n",
    "g.fig.suptitle(\"Refine\", fontproperties=bold_font, y=1.05, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.05, hspace=0)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dda624-6140-4d7e-be57-9f5beb1dbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/robustness_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63ebc8-7f6c-465b-b8fe-1cbdb8c834d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(fidelity_df, col=\"metric\", sharey=True, sharex=True, col_wrap=3, height=4, aspect=.95)\n",
    "for ax, (metric, sub_df) in zip(g.axes.flat, fidelity_df.groupby(\"metric\")):\n",
    "    pivot_percent = sub_df.pivot(index=\"model\", columns=\"score\", values=\"percent\").fillna(0)\n",
    "    pivot_count = sub_df.pivot(index=\"model\", columns=\"score\", values=\"count\").fillna(0)\n",
    "    all_counts.setdefault(mitigation, {})[metric] = pivot_count\n",
    "    bars = pivot_count.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "        # Annotate bars with frequency count\n",
    "    for container, score in zip(bars.containers, pivot_percent.columns):\n",
    "        for rect, count in zip(container, pivot_percent[score]):\n",
    "            if count > 0:  # Only show for non-zero counts\n",
    "                height = rect.get_y() + rect.get_height() / 2\n",
    "                ax.text(rect.get_x() + rect.get_width() / 2, height, f\"{int(count)}\", \n",
    "                        ha='center', va='center', fontsize=14, color=\"black\", fontproperties=bold_font)\n",
    "    ax.vlines([2.5, 5.5], 0, 27, lw=1, color=\"black\", linestyles=\"-\")\n",
    "    #if \"xp\" in metric:\n",
    "    sec2 = ax.secondary_xaxis(location=0)\n",
    "    sec2.set_xticks([2.5, 5.5], labels=[])\n",
    "    sec2.tick_params('x', length=80, width=1, grid_linestyle=\"dashed\")\n",
    "    #ax.set_xlim(-0.1, 9.1)\n",
    "    ax.set_title(rename_metrics[metric], fontproperties=bold_font, fontsize=18)\n",
    "    ax.set_ylabel(\"# of Tasks\", fontsize=18)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    ax.xaxis.set_tick_params(labelsize=16)\n",
    "\n",
    "#g.axes.flat[0].legend(loc='lower right',  bbox_to_anchor=(1.85, -.85), ncol=1)\n",
    "g.fig.suptitle(\"Refine\", fontproperties=bold_font, y=1.1, fontsize=20)\n",
    "plt.subplots_adjust(wspace=.07, hspace=.25)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd8226-98b6-409d-947a-32030bbd2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/fidelity_aggregate_{mitigation}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76981421-6225-4548-be2f-c5d915f1d5e5",
   "metadata": {},
   "source": [
    "### Metric comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef71f23-052c-4565-9183-93da0885cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\n",
    "    \"base\": \"Base\",\n",
    "    \"instruction\": \"Instruction\",\n",
    "    \"refine_basic\": \"Refine\",\n",
    "    \"refine\": \"Ref. + Inst\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de473b-5637-4ef7-9b61-51e79f98892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics = {}\n",
    "for method in all_counts.keys():\n",
    "    agg_metrics.setdefault(method, {})[\"Exp. Advantage\"] = (all_counts[method][\"OP\"] +  all_counts[method][\"level1\"] + all_counts[method][\"level2\"] + all_counts[method][\"level3\"])/27/4\n",
    "    agg_metrics[method][\"Robustness\"] = (all_counts[method][\"WU_color\"] +  all_counts[method][\"WU_name\"])/27/2\n",
    "    agg_metrics[method][\"Fidelity\"] = sum([x for k, x in all_counts[method].items() if \"Fid\" in k])/27/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9a222-5d47-4857-bbf1-b32e06cb9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in agg_metrics.keys():\n",
    "    for m in agg_metrics[method].keys():\n",
    "        agg_metrics[method][m][\"method\"] = method\n",
    "        agg_metrics[method][m][\"metric\"] =  m\n",
    "    agg_metrics[method] = pd.concat(agg_metrics[method].values(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec56c57-0660-4fad-93f1-b36171eb6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics_df = pd.concat(agg_metrics.values(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5dd71-435b-49b2-8047-03c30d82905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_metrics_df.method = agg_metrics_df.method.apply(lambda x: rename[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0941b-0432-40cb-a517-e87a9487611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "df = agg_metrics_df.reset_index()\n",
    "df_melted = df.melt(\n",
    "    id_vars=[\"model\", \"method\", \"metric\"],\n",
    "    value_vars=[\"Negative\", \"Not significant\", \"Positive\"],\n",
    "    var_name=\"score\",\n",
    "    value_name=\"value\"\n",
    ")\n",
    "\n",
    "# Optional: ensure ordering\n",
    "model_order = [\n",
    "    \"gemma-2-2b\", \"gemma-2-9b\", \"gemma-2-27b\",\n",
    "    \"Llama-3.2-3B\", \"Llama-3.1-8B\", \"Llama-3.1-70B\",\n",
    "    \"Qwen2.5-3B\", \"Qwen2.5-7B\", \"Qwen2.5-72B\"\n",
    "]\n",
    "\n",
    "score_order = [\"Negative\", \"Not significant\", \"Positive\"]\n",
    "\n",
    "# Create label for combined model+method\n",
    "label_order = [f\"{me}|{mo}\" for me, mo in product([x for x in rename.values()],model_order)]\n",
    "metric_order = [\"Exp. Advantage\", \"Robustness\", \"Fidelity\"]\n",
    "method_order = list(rename.values())[1:]\n",
    "df_melted[\"label\"] = df_melted[\"method\"].astype(str) + \"|\" + df_melted[\"model\"].astype(str)\n",
    "label_type = pd.CategoricalDtype(label_order, ordered=True)\n",
    "metric_type = pd.CategoricalDtype(metric_order, ordered=True)\n",
    "method_type = pd.CategoricalDtype(method_order, ordered=True)\n",
    "df_melted[\"label\"] = df_melted[\"label\"].astype(label_type)\n",
    "df_melted[\"metric\"] = df_melted[\"metric\"].astype(metric_type)\n",
    "df_melted = df_melted.sort_values([\"label\", \"metric\"])\n",
    "base_df = df_melted[df_melted.method == \"Base\"]\n",
    "df_melted =  df_melted[df_melted.method != \"Base\"]\n",
    "df_melted[\"method\"] = df_melted[\"method\"].astype(method_type)\n",
    "df_melted = df_melted.sort_values([\"label\", \"method\", \"metric\"])\n",
    "\n",
    "# Create FacetGrid with one subplot per metric\n",
    "g = sns.FacetGrid(df_melted, col=\"method\", row=\"metric\",  sharey=True, height=3, aspect=.95)\n",
    "\n",
    "# Plot stacked bars manually per subplot\n",
    "for ax, ((metric, method), sub_df) in zip(g.axes.flat, df_melted.groupby([\"metric\", \"method\"])):\n",
    "    pivot_df = sub_df.pivot_table(index=\"model\", columns=\"score\", values=\"value\", aggfunc=\"sum\").fillna(0)\n",
    "    pivot_df = pivot_df[score_order]  # reorder columns\n",
    "    pivot_base = base_df[(base_df.metric == metric)]\n",
    "    pivot_base = pivot_base.pivot_table(index=\"model\", columns=\"score\", values=\"value\", aggfunc=\"sum\").fillna(0)\n",
    "    pivot_base[\"lower\"] = pivot_base[\"Negative\"]\n",
    "    pivot_base[\"upper\"] = pivot_base[\"Negative\"] +  pivot_base[\"Not significant\"]\n",
    "    bars = pivot_df.plot(kind=\"bar\", stacked=True, ax=ax, colormap=sns.diverging_palette(260, 30,  l=70, s=100, center='light', as_cmap=True), legend=False)\n",
    "    ax.scatter(data=pivot_base, x=pivot_base.index, y=\"lower\", color=\"blue\", marker=\"_\",s=500,label=None)\n",
    "    ax.scatter(data=pivot_base, x=pivot_base.index, y=\"upper\", color=\"orange\", marker=\"_\",s=500 ,label=None)\n",
    "    ax.scatter(data=pivot_base, x=pivot_base.index, y=\"lower\", color=\"blue\", marker=\"X\",s=50,label=None )\n",
    "    ax.scatter(data=pivot_base, x=pivot_base.index, y=\"upper\", color=\"orange\", marker=\"X\",s=50,label=None )\n",
    "    ax.vlines([2.5, 5.5, 8.5], 0, 1, lw=1, color=\"black\", linestyles=\"dashed\")\n",
    "    ax.set_title(method, fontproperties=bold_font) if metric == \"Exp. Advantage\" else ax.set_title(\"\")\n",
    "    ax.set_ylabel(f\"% of Tasks ({metric})\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Add one legend to the figure\n",
    "#legend = g.axes.flat[1].legend(loc='upper center',  bbox_to_anchor=(.5, 1.3), ncol=3)\n",
    "plt.subplots_adjust(wspace=.07, hspace=.05)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb23031-c898-4441-b13e-e05dd4e38c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.savefig(f\"../persona_performance_paper/media/methods_comp_all.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persona-performance",
   "language": "python",
   "name": "persona-performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
